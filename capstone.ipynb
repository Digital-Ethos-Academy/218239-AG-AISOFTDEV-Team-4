{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17492e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help users log their daily moods and journaling, providing insights into their mental health over time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1015d431",
   "metadata": {},
   "source": [
    "MindFulDay - A mental health check-in web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a string variable named 'features_prompt'.\n",
    "# This prompt should ask the LLM to brainstorm features based on the problem_statement.\n",
    "features_prompt = f\"\"\" \n",
    "Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a mental health check-in app. \n",
    "Format the output as a simple markdown list. \n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# TODO: Create a string variable named 'personas_prompt'.\n",
    "# This prompt should ask the LLM to identify three user personas based on the problem_statement.\n",
    "personas_prompt = f\"\"\" \n",
    "Based on the problem statement: '{problem_statement}', identify and describe three distinct user personas who would interact with this tool. \n",
    "For each persona, describe their role and main goal. \n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e19b8",
   "metadata": {},
   "source": [
    "--- Brainstorming Features ---\n",
    "- Daily mood check-in with customizable mood options  \n",
    "- Guided journaling prompts  \n",
    "- Free-form journal entry  \n",
    "- Mood tracking calendar or timeline  \n",
    "- Mood analytics and visualizations (charts, graphs)  \n",
    "- Tagging emotions or themes for entries  \n",
    "- Reminders/notifications for daily check-ins  \n",
    "- Streak tracking for consistent use  \n",
    "- Insights and trends over time (e.g., most common moods, triggers)  \n",
    "- Goal setting (e.g., mood improvement, journaling frequency)  \n",
    "- Coping strategies and mental health resources  \n",
    "- Secure login and data privacy controls  \n",
    "- Option to export or backup journal data  \n",
    "- Integration with wearable devices (sleep, activity data)  \n",
    "- Gratitude journaling section  \n",
    "- Customizable journaling prompts  \n",
    "- Support for adding photos or voice notes to entries  \n",
    "- Crisis support links or quick access  \n",
    "- Mood correlation with external factors (weather, sleep, exercise)  \n",
    "- Dark mode for low-light use  \n",
    "- Community or peer support (optional, anonymized)  \n",
    "- Therapist/coach sharing or progress reports (user-controlled)\n",
    "\n",
    "--- Identifying User Personas ---\n",
    "Certainly! Here are three distinct user personas for the mood and journaling tool:\n",
    "\n",
    "---\n",
    "\n",
    "**1. Persona: Emma, The Busy Professional**\n",
    "\n",
    "- **Role:**  \n",
    "  Emma is a 32-year-old project manager at a tech company. She juggles tight deadlines, frequent meetings, and a busy social life. Her days are packed, and she often feels stressed but wants to be more mindful of her mental health.\n",
    "\n",
    "- **Main Goal:**  \n",
    "  Emma’s main goal is to quickly log her mood and jot down brief reflections throughout her day, using the tool’s analytics to spot trends and triggers affecting her well-being. She wants actionable insights she can use to reduce stress and improve work-life balance.\n",
    "\n",
    "---\n",
    "\n",
    "**2. Persona: Carlos, The College Student**\n",
    "\n",
    "- **Role:**  \n",
    "  Carlos is a 20-year-old university sophomore. He’s navigating academic pressures, social changes, and personal growth. He’s in therapy and uses digital tools to support his mental health journey.\n",
    "\n",
    "- **Main Goal:**  \n",
    "  Carlos wants to use the tool to track his moods alongside major events (exams, social outings, therapy sessions) and journal about his experiences. He seeks visualizations and insights to discuss with his therapist and to better understand patterns in his emotional well-being.\n",
    "\n",
    "---\n",
    "\n",
    "**3. Persona: Linda, The Reflective Retiree**\n",
    "\n",
    "- **Role:**  \n",
    "  Linda is a 67-year-old retired teacher. She values self-reflection and is keen on maintaining her mental health as she adjusts to a new routine. She has time to write and enjoys reviewing her emotional journey.\n",
    "\n",
    "- **Main Goal:**  \n",
    "  Linda’s main goal is to use the tool for in-depth journaling and mood tracking over weeks and months. She appreciates detailed insights and visual summaries to reflect on her progress and share with her close family or counselor if she chooses.\n",
    "\n",
    "---\n",
    "\n",
    "Each persona interacts with the tool differently, but all seek to better understand and manage their mental health through mood tracking and journaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a detailed prompt string named 'json_user_stories_prompt'.\n",
    "# This prompt needs to instruct the LLM to act as a Senior Product Manager and convert the\n",
    "# brainstormed features and personas into a structured JSON array of user stories.\n",
    "# Tip: Be very specific about the required JSON format in your prompt instructions. Tell it what keys to use and what the data types should be.\n",
    "json_user_stories_prompt = f\"\"\" \n",
    "You are a Senior Product Manager tasked with generating user stories for a new mental health check-in app.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of detailed user stories for each user.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Let's try to parse the JSON to see if the LLM followed instructions\n",
    "try:\n",
    "    # The LLM might wrap the JSON in markdown fences (```json ... ```).\n",
    "    # We'll clean that up before parsing.\n",
    "    if '```' in json_output_str:\n",
    "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
    "    \n",
    "    user_stories_json = json.loads(json_output_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    \n",
    "    if user_stories_json:\n",
    "        print(\"\\n--- Sample User Story ---\")\n",
    "        print(json.dumps(user_stories_json[0], indent=2))\n",
    "    else:\n",
    "        print(\"JSON array is empty.\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4708fb",
   "metadata": {},
   "source": [
    "--- Generating User Stories as JSON ---\n",
    "Successfully parsed LLM output as JSON.\n",
    "\n",
    "--- Sample User Story ---\n",
    "{\n",
    "[\n",
    "  {\n",
    "    \"id\": 1,\n",
    "    \"persona\": \"Emma, The Busy Professional\",\n",
    "    \"user_story\": \"As a busy professional, I want to quickly log my mood each day with customizable options, so that I can efficiently track my emotional state without interrupting my schedule.\",\n",
    "    \"acceptance_criteria\": [\n",
    "      \"Given I open the app, When I tap on the mood check-in, Then I can select from a list of mood options or add my own custom mood.\",\n",
    "      \"Given I have logged my mood, When I return to the home screen, Then my mood entry is saved and visible for today.\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": 2,\n",
    "    \"persona\": \"Emma, The Busy Professional\",\n",
    "    \"user_story\": \"As a busy professional, I want to view analytics and trends about my moods, so that I can identify stress triggers and patterns over time.\",\n",
    "    \"acceptance_criteria\": [\n",
    "      \"Given I have logged moods for at least a week, When I view the analytics section, Then I see charts or graphs showing my most common moods and mood changes over time.\",\n",
    "      \"Given I select a specific mood, When I view details, Then I see associated tags or triggers from my entries.\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": 3,\n",
    "    \"persona\": \"Carlos, The College Student\",\n",
    "    \"user_story\": \"As a college student, I want to use guided journaling prompts, so that I can reflect more deeply on my experiences and emotions.\",\n",
    "    \"acceptance_criteria\": [\n",
    "      \"Given I start a new journal entry, When I choose guided prompts, Then the app presents me with relevant questions or topics to write about.\",\n",
    "      \"Given I complete a prompt, When I save my entry, Then my responses are stored and can be reviewed later.\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5e87d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a simple PRD.\n",
    "simple_prd_prompt = f\"\"\"\n",
    "You are a Product Manager tasked with creating a simple Product Requirements Document (PRD) for a mental health check-in app.\n",
    "Based on the following user stories, generate a concise PRD that includes:\n",
    "<user_stories_data>\n",
    "{user_stories_data}\n",
    "<user_stories_data>\n",
    "Use this information to generate Product Requirements Documents with three sections\n",
    "1. Introduction - introduction to the project and it's purpose\n",
    "2. User Personas - brief overview of key people involved\n",
    "3. Features/User stories - list of the user stores and their acceptance criteria\n",
    "\n",
    "Ensure the PRD is for a desktop application that allows users to log their daily moods and journaling, providing insights into their mental health over time.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Simple PRD ---\")\n",
    "if user_stories_data:\n",
    "    simple_prd_output = get_completion(simple_prd_prompt, client, model_name, api_provider)\n",
    "    print(simple_prd_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab4fd9",
   "metadata": {},
   "source": [
    "--- Generating Simple PRD ---\n",
    "**Product Requirements Document (PRD)**  \n",
    "**Mental Health Check-In Desktop Application**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "The Mental Health Check-In desktop application is designed to empower users to monitor and improve their emotional well-being. With quick mood logging, guided journaling, and insightful analytics, the app aims to provide busy individuals and students with efficient tools to track, reflect, and gain actionable insights into their mental health over time. The desktop platform allows for seamless integration into users’ daily routines, offering a private space for self-reflection and personal growth.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. User Personas\n",
    "\n",
    "**Emma, The Busy Professional**  \n",
    "Emma is a career-driven individual with a packed schedule. She values efficiency and needs a quick, non-intrusive way to log her moods and track emotional patterns. Emma is interested in analytics that can help her identify stress triggers and make informed lifestyle adjustments.\n",
    "\n",
    "**Carlos, The College Student**  \n",
    "Carlos is an undergraduate student juggling coursework and social life. He seeks tools to help him reflect on his experiences and emotions. Guided prompts and journaling features support Carlos in processing his thoughts and understanding his emotional journey.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Features / User Stories\n",
    "\n",
    "**User Story 1**  \n",
    "*As a busy professional, I want to quickly log my mood each day with customizable options, so that I can efficiently track my emotional state without interrupting my schedule.*\n",
    "\n",
    "- **Acceptance Criteria:**\n",
    "    - Given I open the app, when I tap on the mood check-in, then I can select from a list of mood options or add my own custom mood.\n",
    "    - Given I have logged my mood, when I return to the home screen, then my mood entry is saved and visible for today.\n",
    "\n",
    "---\n",
    "\n",
    "**User Story 2**  \n",
    "*As a busy professional, I want to view analytics and trends about my moods, so that I can identify stress triggers and patterns over time.*\n",
    "\n",
    "- **Acceptance Criteria:**\n",
    "    - Given I have logged moods for at least a week, when I view the analytics section, then I see charts or graphs showing my most common moods and mood changes over time.\n",
    "    - Given I select a specific mood, when I view details, then I see associated tags or triggers from my entries.\n",
    "\n",
    "---\n",
    "\n",
    "**User Story 3**  \n",
    "*As a college student, I want to use guided journaling prompts, so that I can reflect more deeply on my experiences and emotions.*\n",
    "\n",
    "- **Acceptance Criteria:**\n",
    "    - Given I start a new journal entry, when I choose guided prompts, then the app presents me with relevant questions or topics to write about.\n",
    "    - Given I complete a prompt, when I save my entry, then my responses are stored and can be reviewed later.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PRD template\n",
    "prd_template_content = load_artifact(\"templates/prd_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to populate the PRD template.\n",
    "template_prd_prompt = f\"\"\"\n",
    "You are a Product Manager tasked with generating a Product Requirements Document (PRD) for a mental health check-in app.\n",
    "Based on the following user stories, fill in the provided PRD template with the relevant information:\n",
    "<user_stories_data>\n",
    "{user_stories_data}\n",
    "<user_stories_data>\n",
    "Use the following PRD template:\n",
    "{prd_template_content}\n",
    "\n",
    "This will be a full stack web application that allows users to log their daily moods and journaling, providing insights into their mental health over time. \n",
    "It will be built with Python and FastAPI for the backend, and React for the frontend.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating PRD from Template ---\")\n",
    "if user_stories_data and prd_template_content:\n",
    "    prd_from_template_output = get_completion(template_prd_prompt, client, model_name, api_provider)\n",
    "    print(prd_from_template_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories or template are missing.\")\n",
    "    prd_from_template_output = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988d3228",
   "metadata": {},
   "source": [
    "--- Generating PRD from Template ---\n",
    "# Product Requirements Document: MindfulDay – Mental Health Check-in App\n",
    "\n",
    "| Status | **Draft** |\n",
    "| :--- | :--- |\n",
    "| **Author** | Product Team |\n",
    "| **Version** | 1.0 |\n",
    "| **Last Updated** | 2024-06-12 |\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Executive Summary & Vision\n",
    "MindfulDay is a web-based mental health check-in app designed to help users efficiently log their moods, reflect on their feelings, and gain actionable insights into their emotional wellbeing. By offering quick mood logging, guided journaling, and trend analytics, MindfulDay empowers busy professionals, students, and anyone seeking greater mental health awareness to build healthy self-reflection habits. Our vision is to create an accessible, data-driven platform that supports users in identifying stressors and fostering long-term emotional resilience.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Problem\n",
    "\n",
    "### 2.1. Problem Statement\n",
    "Modern life presents increasing emotional challenges, yet most people lack tools for quick, regular self-reflection. Existing solutions are often time-consuming or fail to provide actionable feedback, making it difficult for users with busy schedules to track and understand their mental health patterns.\n",
    "\n",
    "### 2.2. User Personas & Scenarios\n",
    "\n",
    "- **Persona 1: Emma, The Busy Professional**  \n",
    "  Emma juggles a demanding job and a hectic schedule. She wants to quickly log her mood during short breaks, customize mood tags, and see patterns to better manage work-related stress.\n",
    "\n",
    "- **Persona 2: Carlos, The College Student**  \n",
    "  Carlos faces academic pressures and personal growth challenges. He seeks guided prompts to help him journal deeply about his feelings and experiences for greater self-understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Goals & Success Metrics\n",
    "\n",
    "| Goal | Key Performance Indicator (KPI) | Target |\n",
    "| :--- | :--- | :--- |\n",
    "| Increase Daily Engagement | % of users logging a mood at least 5 days/week | 60% |\n",
    "| Facilitate Self-Reflection | % of active users using guided journaling prompts weekly | 40% |\n",
    "| Deliver Actionable Insights | % of users viewing analytics at least once per week | 50% |\n",
    "| Improve Retention | Day-30 user retention rate | 35% |\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Functional Requirements & User Stories\n",
    "\n",
    "### Epic: Mood Logging & Customization\n",
    "\n",
    "* **Story 1.1:** As Emma, the busy professional, I want to quickly log my mood each day with customizable options, so that I can efficiently track my emotional state without interrupting my schedule.  \n",
    "  * **Acceptance Criteria:**\n",
    "      * **Given** I open the app, **When** I tap on the mood check-in, **Then** I can select from a list of mood options or add my own custom mood.\n",
    "      * **Given** I have logged my mood, **When** I return to the home screen, **Then** my mood entry is saved and visible for today.\n",
    "\n",
    "---\n",
    "\n",
    "### Epic: Mood Analytics & Trends\n",
    "\n",
    "* **Story 2.1:** As Emma, the busy professional, I want to view analytics and trends about my moods, so that I can identify stress triggers and patterns over time.  \n",
    "  * **Acceptance Criteria:**\n",
    "      * **Given** I have logged moods for at least a week, **When** I view the analytics section, **Then** I see charts or graphs showing my most common moods and mood changes over time.\n",
    "      * **Given** I select a specific mood, **When** I view details, **Then** I see associated tags or triggers from my entries.\n",
    "\n",
    "---\n",
    "\n",
    "### Epic: Guided Journaling\n",
    "\n",
    "* **Story 3.1:** As Carlos, the college student, I want to use guided journaling prompts, so that I can reflect more deeply on my experiences and emotions.  \n",
    "  * **Acceptance Criteria:**\n",
    "      * **Given** I start a new journal entry, **When** I choose guided prompts, **Then** the app presents me with relevant questions or topics to write about.\n",
    "      * **Given** I complete a prompt, **When** I save my entry, **Then** my responses are stored and can be reviewed later.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Non-Functional Requirements (NFRs)\n",
    "\n",
    "- **Performance:** The app must load the main dashboard in under 3 seconds on a standard broadband or mobile connection.\n",
    "- **Security:** All user data must be encrypted in transit (TLS) and at rest. The system must support secure user authentication.\n",
    "- **Accessibility:** The UI must comply with WCAG 2.1 AA standards to ensure accessibility for all users.\n",
    "- **Scalability:** The system must support at least 10,000 concurrent users with no degradation in performance.\n",
    "- **Privacy:** User data must never be shared with third parties without explicit consent.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Release Plan & Milestones\n",
    "\n",
    "- **Version 1.0 (MVP):** 2024-08-15  \n",
    "  - Core features: mood logging (incl. custom moods), mood history, basic analytics, guided journaling prompts, secure account management.\n",
    "- **Version 1.1:** 2024-10-01  \n",
    "  - Enhanced analytics, mood triggers/tags, expanded journaling prompt library, improved onboarding.\n",
    "- **Version 2.0:** 2025-01-15  \n",
    "  - Social features (peer support opt-in), reminders & notifications, integrations (e.g., calendar), advanced insights.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Out of Scope & Future Considerations\n",
    "\n",
    "### 7.1. Out of Scope for V1.0\n",
    "- Integration with third-party wellness or HR systems.\n",
    "- Gamification features (badges, streaks, etc.).\n",
    "- Native mobile apps (web app will be mobile-responsive).\n",
    "- Real-time chat or therapist connection.\n",
    "\n",
    "### 7.2. Future Work\n",
    "- AI-powered mood and journal analysis for personalized recommendations.\n",
    "- Support for group check-ins or shared analytics (e.g., for teams or families).\n",
    "- Integration with wearable devices for passive mood detection.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Appendix & Open Questions\n",
    "\n",
    "- **Dependency:** Final UI/UX design required from Design Team by 2024-07-01.\n",
    "- **Open Question:** Should users be able to export their mood and journal data (e.g., PDF, CSV) in V1.0?\n",
    "- **Assumption:** Users will be required to register and authenticate to save their check-ins and analytics.\n",
    "- **Dependency:** Content team to supply initial set of guided journaling prompts by 2024-07-15.\n",
    "\n",
    "---\n",
    "\n",
    "**Tech Stack:**  \n",
    "Backend: Python + FastAPI  \n",
    "Frontend: React  \n",
    "Deployment: Full-stack web application, mobile-responsive design\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e72bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a Pydantic model for the PRD.\n",
    "# Tip: Be specific. Tell the LLM to create a class named 'ProductRequirementsDocument' and to use appropriate types from Python's 'typing' library.\n",
    "pydantic_model_prompt = f\"\"\"\n",
    "You are a Senior Software Engineer tasked with generating a Pydantic model for a Product Requirements Document (PRD) for a mental health check-in app.\n",
    "Based on the following PRD template, generate a Pydantic model that captures the structure of the PRD:\n",
    "<prd_template_content> \n",
    "{prd_template_content}\n",
    "<prd_template_content>\n",
    "The Pydantic model should include fields for:\n",
    "1. Introduction - a string field for the project introduction.\n",
    "2. User Personas - a list of strings for the user personas.\n",
    "3. Features/User Stories - a list of dictionaries, each containing:\n",
    "- id: an integer for the user story ID.\n",
    "- persona: a string for the user persona.\n",
    "- user_story: a string for the user story description.\n",
    "- acceptance_criteria: a list of strings for the acceptance criteria.\n",
    "Generate the Pydantic model code in Python, ensuring it is well-structured and follows best practices for type annotations.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Pydantic Model for PRD ---\")\n",
    "if prd_template_content:\n",
    "    pydantic_model_code = get_completion(pydantic_model_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the code if it's wrapped in markdown fences\n",
    "    if '```' in pydantic_model_code:\n",
    "        pydantic_model_code = pydantic_model_code.split('```')[1].lstrip('python').strip()\n",
    "    \n",
    "    print(\"\\n--- Generated Pydantic Model ---\")\n",
    "    print(pydantic_model_code)\n",
    "\n",
    "    # Save the generated Pydantic model code to a file.\n",
    "    model_path = \"app/validation_models/prd_model.py\"\n",
    "    save_artifact(pydantic_model_code, model_path)\n",
    "else:\n",
    "    print(\"Skipping Pydantic model generation because template is missing.\")\n",
    "\n",
    "# Finally, save the completed PRD from the intermediate challenge\n",
    "if prd_from_template_output:\n",
    "    save_artifact(prd_from_template_output, \"capstone/day1_prd.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95165695",
   "metadata": {},
   "source": [
    "--- Generating Pydantic Model for PRD ---\n",
    "\n",
    "--- Generated Pydantic Model ---\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class UserStory(BaseModel):\n",
    "    id: int = Field(..., description=\"Unique identifier for the user story\")\n",
    "    persona: str = Field(..., description=\"User persona for whom the story is written\")\n",
    "    user_story: str = Field(..., description=\"Description of the user story\")\n",
    "    acceptance_criteria: List[str] = Field(\n",
    "        ..., description=\"List of acceptance criteria for the user story\"\n",
    "    )\n",
    "\n",
    "\n",
    "class PRDModel(BaseModel):\n",
    "    introduction: str = Field(\n",
    "        ..., description=\"Project introduction and executive summary\"\n",
    "    )\n",
    "    user_personas: List[str] = Field(\n",
    "        ..., description=\"List of user personas relevant to the product\"\n",
    "    )\n",
    "    features_user_stories: List[UserStory] = Field(\n",
    "        ..., description=\"List of user stories with details\"\n",
    "    )\n",
    "✅ Successfully saved artifact to: app/validation_models/prd_model.py\n",
    "✅ Successfully saved artifact to: capstone/day1_prd.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f3d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate the SQL schema from the PRD.\n",
    "schema_prompt = f\"\"\"\n",
    "You are an expert Database Administrator.\n",
    "Take the following Product Requirements Document{prd_content}, design a normalized SQL schema for a SQLite database. \n",
    "The schema should include tables for users, their moods and their journals.\n",
    "\n",
    "The schema should have at least a `users` table a `journal` table and a `moods` table with a foreign key relationship.\n",
    "Output only the raw SQL `CREATE TABLE` statements.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    generated_schema = get_completion(schema_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated schema using our helper function\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "    \n",
    "    # Save the cleaned schema\n",
    "    save_artifact(cleaned_schema, 'artifacts/schema.sql')\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0d165",
   "metadata": {},
   "source": [
    "--- Generating SQL Schema ---\n",
    "CREATE TABLE users (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    email TEXT NOT NULL UNIQUE,\n",
    "    password_hash TEXT NOT NULL,\n",
    "    display_name TEXT,\n",
    "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "CREATE TABLE moods (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_id INTEGER NOT NULL,\n",
    "    mood TEXT NOT NULL,\n",
    "    mood_date DATE NOT NULL,\n",
    "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE\n",
    ");\n",
    "\n",
    "CREATE TABLE journal (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    user_id INTEGER NOT NULL,\n",
    "    entry_date DATE NOT NULL,\n",
    "    prompt TEXT,\n",
    "    content TEXT NOT NULL,\n",
    "    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,\n",
    "    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE\n",
    ");\n",
    "✅ Successfully saved artifact to: artifacts/schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate realistic seed data.\n",
    "seed_data_prompt = f\"\"\"\n",
    "You are a data specialist. Based on the provided PRD{prd_content} and SQL{cleaned_schema} schema, generate 5 SQL `INSERT` statements to populate the tables with sample data for a mental health journaling application.\n",
    "Generate 3 users and 5 moods assigned to those users.\n",
    "Output only the raw SQL `INSERT` statements.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    generated_seed_data = get_completion(seed_data_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "    \n",
    "    # Save the cleaned seed data\n",
    "    save_artifact(cleaned_seed_data, 'artifacts/seed_data.sql')\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cfffd2",
   "metadata": {},
   "source": [
    "--- Generating Seed Data ---\n",
    "INSERT INTO users (email, password_hash, display_name) VALUES\n",
    "('emma.smith@example.com', 'hash1', 'Emma Smith'),\n",
    "('carlos.garcia@example.com', 'hash2', 'Carlos Garcia'),\n",
    "('alex.johnson@example.com', 'hash3', 'Alex Johnson');\n",
    "\n",
    "INSERT INTO moods (user_id, mood, mood_date) VALUES\n",
    "(1, 'Stressed', '2025-07-24'),\n",
    "(1, 'Productive', '2025-07-25'),\n",
    "(2, 'Anxious', '2025-07-25'),\n",
    "(2, 'Motivated', '2025-07-26'),\n",
    "(3, 'Content', '2025-07-25');\n",
    "✅ Successfully saved artifact to: artifacts/seed_data.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5faa6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "        print(f\"Removed existing database file at {db_path}\")\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        # TODO: Connect to the SQLite database. This will create the file if it doesn't exist.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # TODO: Read the content of the schema file using load_artifact.\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if schema_sql:\n",
    "            cursor.executescript(schema_sql)\n",
    "            print(\"Schema executed successfully.\")\n",
    "\n",
    "        # TODO: Check if the seed data file exists. If it does, load and execute it.\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted successfully.\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed.\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        # TODO: Ensure the connection is closed if it was opened.\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(project_root, \"capstone\", \"mental_health.db\")\n",
    "schema_file = os.path.join(project_root, \"capstone\", \"schema.sql\")\n",
    "seed_file = os.path.join(project_root, \"capstone\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc924e34",
   "metadata": {},
   "source": [
    "Removed existing database file at c:\\Users\\labadmin\\Documents\\AI_Driven_Software_Engineering\\capstone\\mental_health.db\n",
    "Successfully connected to database at c:\\Users\\labadmin\\Documents\\AI_Driven_Software_Engineering\\capstone\\mental_health.db\n",
    "Schema executed successfully.\n",
    "Seed data inserted successfully.\n",
    "Database changes committed.\n",
    "Database connection closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_schema = load_artifact(\"schema.sql\")\n",
    "if not sql_schema:\n",
    "    print(\"Warning: Could not load schema.sql. Lab may not function correctly.\")\n",
    "\n",
    "print(sql_schema)\n",
    "\n",
    "in_memory_api_prompt = f\"\"\"\n",
    "I am a senior python developer and want to leveage FasteAPI to build an Application using an in-memory data storage.\n",
    "\n",
    "There are the key components:\n",
    "1.  Pydantic Models:  For API data validation (request/response bodies).\n",
    "2.  FastAPI Endpoints: Full CRUD (Create, Read, Update, Delete) endpoints for the `users`, `moods`,  `journal`  and `prompts` table.\n",
    "3.  In-Memory Database: A simple Python list to act as a temporary, fake database.\n",
    "\n",
    "Here is the SQL Schema between the bracks <code>\n",
    "\n",
    "<code>\n",
    "{sql_schema}\n",
    "</code>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating FastAPI app with in-memory database ---\")\n",
    "if sql_schema:\n",
    "    generated_api_code = get_completion(in_memory_api_prompt, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_api_code, language='python')\n",
    "    print(cleaned_code)\n",
    "    save_artifact(cleaned_code, \"app/main_in_memory.py\")\n",
    "else:\n",
    "    print(\"Skipping API generation because schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a419642",
   "metadata": {},
   "source": [
    "--- Generating FastAPI app with in-memory database ---\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, EmailStr, Field\n",
    "from typing import Optional, List\n",
    "from datetime import datetime, date\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# IN-MEMORY DATABASE\n",
    "db = {\n",
    "    \"users\": [],\n",
    "    \"moods\": [],\n",
    "    \"journal\": [],\n",
    "    \"prompts\": []\n",
    "}\n",
    "id_counters = {\n",
    "    \"users\": 1,\n",
    "    \"moods\": 1,\n",
    "    \"journal\": 1,\n",
    "    \"prompts\": 1,\n",
    "}\n",
    "\n",
    "# =====================\n",
    "#   Pydantic MODELS\n",
    "# =====================\n",
    "\n",
    "# USERS\n",
    "class UserBase(BaseModel):\n",
    "    email: EmailStr\n",
    "    display_name: Optional[str] = None\n",
    "\n",
    "class UserCreate(UserBase):\n",
    "    password: str = Field(..., min_length=6)\n",
    "\n",
    "class User(UserBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "    updated_at: Optional[datetime] = None\n",
    "\n",
    "# MOODS\n",
    "class MoodBase(BaseModel):\n",
    "    user_id: int\n",
    "    mood: str\n",
    "    mood_date: date\n",
    "\n",
    "class MoodCreate(MoodBase):\n",
    "    pass\n",
    "\n",
    "class Mood(MoodBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "# PROMPTS\n",
    "class PromptBase(BaseModel):\n",
    "    prompt_text: str\n",
    "\n",
    "class PromptCreate(PromptBase):\n",
    "    pass\n",
    "\n",
    "class Prompt(PromptBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "# JOURNAL\n",
    "class JournalBase(BaseModel):\n",
    "    user_id: int\n",
    "    prompt_id: Optional[int] = None\n",
    "    entry_date: date\n",
    "    content: str\n",
    "\n",
    "class JournalCreate(JournalBase):\n",
    "    pass\n",
    "\n",
    "class Journal(JournalBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "# =====================\n",
    "#   UTILITY FUNCTIONS\n",
    "# =====================\n",
    "def get_next_id(table: str) -> int:\n",
    "    val = id_counters[table]\n",
    "    id_counters[table] += 1\n",
    "    return val\n",
    "\n",
    "def find_by_id(table: str, id_: int):\n",
    "    for item in db[table]:\n",
    "        if item['id'] == id_:\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "def remove_by_id(table: str, id_: int):\n",
    "    for i, item in enumerate(db[table]):\n",
    "        if item['id'] == id_:\n",
    "            del db[table][i]\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# =====================\n",
    "#   USERS ENDPOINTS\n",
    "# =====================\n",
    "@app.post(\"/users/\", response_model=User)\n",
    "def create_user(user: UserCreate):\n",
    "    # Check for unique email\n",
    "    if any(u['email'] == user.email for u in db[\"users\"]):\n",
    "        raise HTTPException(status_code=400, detail=\"Email already registered\")\n",
    "    user_dict = user.dict()\n",
    "    user_dict[\"id\"] = get_next_id(\"users\")\n",
    "    user_dict[\"password_hash\"] = user_dict.pop(\"password\")  # Fake hash\n",
    "    now = datetime.utcnow()\n",
    "    user_dict[\"created_at\"] = now\n",
    "    user_dict[\"updated_at\"] = now\n",
    "    db[\"users\"].append(user_dict)\n",
    "    return User(**user_dict)\n",
    "\n",
    "@app.get(\"/users/\", response_model=List[User])\n",
    "def list_users():\n",
    "    return [User(**{k: v for k, v in user.items() if k != \"password_hash\"}) for user in db[\"users\"]]\n",
    "\n",
    "@app.get(\"/users/{user_id}\", response_model=User)\n",
    "def get_user(user_id: int):\n",
    "    user = find_by_id(\"users\", user_id)\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    user = {k: v for k, v in user.items() if k != \"password_hash\"}\n",
    "    return User(**user)\n",
    "\n",
    "@app.put(\"/users/{user_id}\", response_model=User)\n",
    "def update_user(user_id: int, user: UserBase):\n",
    "    existing = find_by_id(\"users\", user_id)\n",
    "    if not existing:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    existing.update(user.dict())\n",
    "    existing[\"updated_at\"] = datetime.utcnow()\n",
    "    return User(**{k: v for k, v in existing.items() if k != \"password_hash\"})\n",
    "\n",
    "@app.delete(\"/users/{user_id}\")\n",
    "def delete_user(user_id: int):\n",
    "    if not remove_by_id(\"users\", user_id):\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    # Cascade delete moods and journals\n",
    "    db[\"moods\"] = [m for m in db[\"moods\"] if m[\"user_id\"] != user_id]\n",
    "    db[\"journal\"] = [j for j in db[\"journal\"] if j[\"user_id\"] != user_id]\n",
    "    return {\"msg\": \"Deleted\"}\n",
    "\n",
    "# =====================\n",
    "#   MOODS ENDPOINTS\n",
    "# =====================\n",
    "@app.post(\"/moods/\", response_model=Mood)\n",
    "def create_mood(mood: MoodCreate):\n",
    "    # Check user exists\n",
    "    if not find_by_id(\"users\", mood.user_id):\n",
    "        raise HTTPException(status_code=400, detail=\"User does not exist\")\n",
    "    mood_dict = mood.dict()\n",
    "    mood_dict[\"id\"] = get_next_id(\"moods\")\n",
    "    mood_dict[\"created_at\"] = datetime.utcnow()\n",
    "    db[\"moods\"].append(mood_dict)\n",
    "    return Mood(**mood_dict)\n",
    "\n",
    "@app.get(\"/moods/\", response_model=List[Mood])\n",
    "def list_moods():\n",
    "    return [Mood(**m) for m in db[\"moods\"]]\n",
    "\n",
    "@app.get(\"/moods/{mood_id}\", response_model=Mood)\n",
    "def get_mood(mood_id: int):\n",
    "    mood = find_by_id(\"moods\", mood_id)\n",
    "    if not mood:\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    return Mood(**mood)\n",
    "\n",
    "@app.put(\"/moods/{mood_id}\", response_model=Mood)\n",
    "def update_mood(mood_id: int, mood: MoodBase):\n",
    "    existing = find_by_id(\"moods\", mood_id)\n",
    "    if not existing:\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    existing.update(mood.dict())\n",
    "    return Mood(**existing)\n",
    "\n",
    "@app.delete(\"/moods/{mood_id}\")\n",
    "def delete_mood(mood_id: int):\n",
    "    if not remove_by_id(\"moods\", mood_id):\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    return {\"msg\": \"Deleted\"}\n",
    "\n",
    "# =====================\n",
    "#   PROMPTS ENDPOINTS\n",
    "# =====================\n",
    "@app.post(\"/prompts/\", response_model=Prompt)\n",
    "def create_prompt(prompt: PromptCreate):\n",
    "    prompt_dict = prompt.dict()\n",
    "    prompt_dict[\"id\"] = get_next_id(\"prompts\")\n",
    "    prompt_dict[\"created_at\"] = datetime.utcnow()\n",
    "    db[\"prompts\"].append(prompt_dict)\n",
    "    return Prompt(**prompt_dict)\n",
    "\n",
    "@app.get(\"/prompts/\", response_model=List[Prompt])\n",
    "def list_prompts():\n",
    "    return [Prompt(**p) for p in db[\"prompts\"]]\n",
    "\n",
    "@app.get(\"/prompts/{prompt_id}\", response_model=Prompt)\n",
    "def get_prompt(prompt_id: int):\n",
    "    prompt = find_by_id(\"prompts\", prompt_id)\n",
    "    if not prompt:\n",
    "        raise HTTPException(status_code=404, detail=\"Prompt not found\")\n",
    "    return Prompt(**prompt)\n",
    "\n",
    "@app.put(\"/prompts/{prompt_id}\", response_model=Prompt)\n",
    "def update_prompt(prompt_id: int, prompt: PromptBase):\n",
    "    existing = find_by_id(\"prompts\", prompt_id)\n",
    "    if not existing:\n",
    "        raise HTTPException(status_code=404, detail=\"Prompt not found\")\n",
    "    existing.update(prompt.dict())\n",
    "    return Prompt(**existing)\n",
    "\n",
    "@app.delete(\"/prompts/{prompt_id}\")\n",
    "def delete_prompt(prompt_id: int):\n",
    "    if not remove_by_id(\"prompts\", prompt_id):\n",
    "        raise HTTPException(status_code=404, detail=\"Prompt not found\")\n",
    "    # Cascade delete journals using this prompt\n",
    "    db[\"journal\"] = [j for j in db[\"journal\"] if j[\"prompt_id\"] != prompt_id]\n",
    "    return {\"msg\": \"Deleted\"}\n",
    "\n",
    "# =====================\n",
    "#   JOURNAL ENDPOINTS\n",
    "# =====================\n",
    "@app.post(\"/journal/\", response_model=Journal)\n",
    "def create_journal(journal: JournalCreate):\n",
    "    # Validate user\n",
    "    if not find_by_id(\"users\", journal.user_id):\n",
    "        raise HTTPException(status_code=400, detail=\"User does not exist\")\n",
    "    # Validate prompt (if any)\n",
    "    if journal.prompt_id and not find_by_id(\"prompts\", journal.prompt_id):\n",
    "        raise HTTPException(status_code=400, detail=\"Prompt does not exist\")\n",
    "    journal_dict = journal.dict()\n",
    "    journal_dict[\"id\"] = get_next_id(\"journal\")\n",
    "    journal_dict[\"created_at\"] = datetime.utcnow()\n",
    "    db[\"journal\"].append(journal_dict)\n",
    "    return Journal(**journal_dict)\n",
    "\n",
    "@app.get(\"/journal/\", response_model=List[Journal])\n",
    "def list_journals():\n",
    "    return [Journal(**j) for j in db[\"journal\"]]\n",
    "\n",
    "@app.get(\"/journal/{journal_id}\", response_model=Journal)\n",
    "def get_journal(journal_id: int):\n",
    "    journal = find_by_id(\"journal\", journal_id)\n",
    "    if not journal:\n",
    "        raise HTTPException(status_code=404, detail=\"Journal not found\")\n",
    "    return Journal(**journal)\n",
    "\n",
    "@app.put(\"/journal/{journal_id}\", response_model=Journal)\n",
    "def update_journal(journal_id: int, journal: JournalBase):\n",
    "    existing = find_by_id(\"journal\", journal_id)\n",
    "    if not existing:\n",
    "        raise HTTPException(status_code=404, detail=\"Journal not found\")\n",
    "    if journal.prompt_id and not find_by_id(\"prompts\", journal.prompt_id):\n",
    "        raise HTTPException(status_code=400, detail=\"Prompt does not exist\")\n",
    "    existing.update(journal.dict())\n",
    "    return Journal(**existing)\n",
    "\n",
    "@app.delete(\"/journal/{journal_id}\")\n",
    "def delete_journal(journal_id: int):\n",
    "    if not remove_by_id(\"journal\", journal_id):\n",
    "        raise HTTPException(status_code=404, detail=\"Journal not found\")\n",
    "    return {\"msg\": \"Deleted\"}\n",
    "✅ Successfully saved artifact to: capstone/main_in_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b7aeb",
   "metadata": {},
   "source": [
    "# ADR Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    # This works when running as a script\n",
    "    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))\n",
    "except NameError:\n",
    "    # This works when running in an interactive environment (like a notebook)\n",
    "    # We go up two levels from the notebook's directory to the project root.\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_artifact\n",
    "from utils import get_completion, save_artifact, setup_llm_client\n",
    "client, model_name, api_provider = setup_llm_client() \n",
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "sql_schema = load_artifact(\"capstone/schema.sql\")\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a Senior Front end engineer. Populate the Architectural Decision Record (ADR) with formal documentation on the decision to utilize\n",
    "the approach of modularizing the webpages into seperate components, each with its own JSX file. The app.jsx file is responsible for routing and the index.jsx file is responsible for rendering the app.\n",
    "\n",
    "\n",
    "use the ADR template to populate an ADR with your justification.\n",
    "***ADR Template***\n",
    "<template>\n",
    "{adr_template}\n",
    "</template>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and sql_schema:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"capstone/adr_002_database_choice.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8145ff18",
   "metadata": {},
   "source": [
    "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
    "--- Synthesizing Final ADR ---\n",
    "---\n",
    "\n",
    "# Architectural Decision Record (ADR)\n",
    "\n",
    "## Title\n",
    "Modularization of Webpages into Separate Components with JSX Files\n",
    "\n",
    "## Status\n",
    "Accepted\n",
    "\n",
    "## Context\n",
    "As the complexity of our web application grows, maintaining and scaling the codebase has become increasingly challenging. A modular approach enables better organization, ease of maintenance, and scalability. The current challenge is to efficiently manage multiple UI views and components while ensuring a clear separation of concerns. This decision is driven by the need to enhance code readability, facilitate component reuse, and streamline the application development process.\n",
    "\n",
    "## Decision\n",
    "The application will adopt a component-based architecture where each webpage is broken down into smaller, reusable components, each housed in its own JSX file. The `app.jsx` file will be responsible for managing routes and navigation across these components, while the `index.jsx` file will handle rendering the root component of the application.\n",
    "\n",
    "## Consequences\n",
    "\n",
    "### Positive Consequences\n",
    "- **Enhanced Maintainability:** Code is organized into distinct, manageable pieces, making it easier to track changes and debug issues.\n",
    "- **Improved Reusability:** Components can be reused across different parts of the application, reducing redundancy and development time.\n",
    "- **Scalability:** The application structure supports the addition of new features without significant rework, accommodating future growth.\n",
    "- **Separation of Concerns:** By isolating routing logic in `app.jsx` and rendering in `index.jsx`, we maintain a clean separation between the application flow and the UI rendering.\n",
    "\n",
    "### Negative Consequences\n",
    "- **Initial Learning Curve:** Developers may need time to adapt to the new architectural style, especially those unfamiliar with component-based architecture.\n",
    "- **Increased Overhead:** Setting up and managing multiple components can introduce additional overhead during the initial development phase.\n",
    "- **Potential for Over-Engineering:** Risk of creating too many small components that complicate rather than simplify the application structure.\n",
    "\n",
    "## Notes\n",
    "This architectural decision aligns with industry best practices for building modern React applications and leverages the strengths of JSX in creating dynamic, component-based UIs.\n",
    "\n",
    "## Related Decisions\n",
    "- ADR for selecting React as the frontend framework, which complements this component-based approach.\n",
    "- ADR regarding the adoption of a state management library for handling application state across components.\n",
    "\n",
    "## Date\n",
    "October 20, 2023\n",
    "\n",
    "## Author\n",
    "[Your Name]\n",
    "\n",
    "---\n",
    "\n",
    "This ADR provides a comprehensive overview of the decision to modularize the application using separate JSX components, detailing the rationale, expected outcomes, and implications of this architectural choice.\n",
    "✅ Successfully saved artifact to: capstone/adr_002_database_choice.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_artifact\n",
    "\n",
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "sql_schema = load_artifact(\"capstone/schema.sql\")\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a Staff Engineer. Populate the Architectural Decision Record (ADR) with formal documentation on the decision to utilize\n",
    "the approach of using SQLlite with a Python FastAPI backend for a mental health check-in web application.\n",
    "\n",
    "Use the following sql schema as the context for your decision:\n",
    "<context>\n",
    "{sql_schema}\n",
    "</context>\n",
    "\n",
    "use the ADR template to populate an ADR with your justification.\n",
    "***ADR Template***\n",
    "<template>\n",
    "{adr_template}\n",
    "</template>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and sql_schema:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"capstone/adr_002_database_choice.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008c41d",
   "metadata": {},
   "source": [
    "# Architectural Decision Record (ADR)\n",
    "\n",
    "## Title\n",
    "Utilization of SQLite with Python FastAPI for Mental Health Check-In Application Backend\n",
    "\n",
    "## Status\n",
    "Accepted\n",
    "\n",
    "## Context\n",
    "The project involves developing a mental health check-in web application to track user moods and journal entries. The application requires a lightweight, self-contained database solution to handle user data, mood tracking, and journaling, aligning with the SQL schema provided. The primary requirements are simplicity, ease of deployment, low maintenance overhead, and compatibility with Python-based frameworks.\n",
    "\n",
    "## Decision\n",
    "The decision is to use SQLite as the database for the backend of the mental health check-in application, implemented using the Python FastAPI framework. SQLite is chosen due to its lightweight nature, ease of use, and seamless integration with Python, which aligns with FastAPI's strengths in building modern web applications. This setup provides a straightforward solution for managing the application's data requirements, including user authentication, mood tracking, and journaling.\n",
    "\n",
    "## Consequences\n",
    "\n",
    "### Positive Consequences\n",
    "- **Simplicity and Ease of Use**: SQLite provides a simple database solution that is easy to set up and requires minimal configuration, making it ideal for a small to medium-scale application like this.\n",
    "- **Portability**: As a self-contained, serverless database, SQLite can be easily integrated and deployed across different environments without additional dependencies.\n",
    "- **Cost-Effective**: No need for a dedicated database server reduces both infrastructure costs and maintenance overhead.\n",
    "- **Rapid Development**: FastAPI, combined with SQLite, allows for rapid development and iteration due to native support in Python, facilitating quick prototyping and deployment.\n",
    "\n",
    "### Negative Consequences\n",
    "- **Scalability Limits**: SQLite may not handle very high concurrent write operations efficiently, which could be a limitation if the application scales significantly in the future.\n",
    "- **Concurrency Constraints**: SQLite uses file locks for concurrency control, which might lead to performance bottlenecks under heavy write loads.\n",
    "- **Limited Advanced Features**: Compared to other database systems like PostgreSQL, SQLite has limited support for advanced features and optimization capabilities.\n",
    "\n",
    "## Notes\n",
    "While SQLite is an excellent choice for the current scale and scope of the project, it may be necessary to consider transitioning to a more robust database system if the application's user base grows significantly.\n",
    "\n",
    "## Related Decisions\n",
    "N/A\n",
    "\n",
    "## Date\n",
    "July 31, 2025\n",
    "\n",
    "## Author\n",
    "Team 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27698f5f",
   "metadata": {},
   "source": [
    "# Frontend Design Mockups\n",
    "\n",
    "Images were generated with chatgpt 4o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec85d9",
   "metadata": {},
   "source": [
    "## Login screen\n",
    "prompt: I am building a mental health check-in web app. Please generate an image for a template of the login screen. reflect the name of the app. it is called MindfulDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070342d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/39rLqXBB/Chat-GPT-Image-Jul-31-2025-01-39-05-PM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from IPython.display import Image, display, Code\n",
    "login_form_url = \"https://i.ibb.co/39rLqXBB/Chat-GPT-Image-Jul-31-2025-01-39-05-PM.png\"\n",
    "display(Image(url=login_form_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68666fa4",
   "metadata": {},
   "source": [
    "## Signup page\n",
    "prompt: Create a page to sign up for the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65b3f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/39rLqXBB/Chat-GPT-Image-Jul-31-2025-01-39-05-PM.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login_form_url = \"https://i.ibb.co/39rLqXBB/Chat-GPT-Image-Jul-31-2025-01-39-05-PM.png\"\n",
    "display(Image(url=login_form_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a6d44",
   "metadata": {},
   "source": [
    "## Main page\n",
    "prompt: Now create a template image for the dashboard when a user logs in. It should include the following:\n",
    "A section to log a user's mood and an analytics dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8edce4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/pvgF3sBW/main-page.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login_form_url = \"https://i.ibb.co/pvgF3sBW/main-page.png\"\n",
    "display(Image(url=login_form_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c24824",
   "metadata": {},
   "source": [
    "## journal page\n",
    "prompt: I now want to add another page. after the user logs their mood, they should be redirected to a page where they respond to a predetermined prompt depending on the mood submitted. Please generate an image of that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a104d961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/4gCfk3Bd/journal-page.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login_form_url = \"https://i.ibb.co/4gCfk3Bd/journal-page.png\"\n",
    "display(Image(url=login_form_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96532694",
   "metadata": {},
   "source": [
    "# Image to React Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c835a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_vision_completion, get_completion, save_artifact, clean_llm_output\n",
    "from IPython.display import Image, display, Code\n",
    "\n",
    "# Ensure you select a vision-capable model\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "if not model_name:\n",
    "    print(\"Could not set up a valid LLM client. Please check your .env file and utils.py configuration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a single React component from the image.\n",
    "generate_ui_prompt = f\"\"\"\n",
    "You are an expert frontend developer with extensive experience in React and Tailwind CSS.\n",
    "Your task is to analyze the provided image of a login form and write the code for a single, self-contained React component that accurately replicates its design and layout.\n",
    "\n",
    "** Requirements: **\n",
    "1. Use functional components\n",
    "2. Use Tailwind CSS for styling, do not use any other CSS framework or custom styles.\n",
    "3. the component should be accessible, using appropriate HTML elements and attributes.\n",
    "4. The output should be a single block of Javascript code for the component.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Monolithic UI Component ---\")\n",
    "generated_monolithic_code = \"\"\n",
    "if model_name:\n",
    "    generated_monolithic_code = get_vision_completion(generate_ui_prompt, login_form_url, client, model_name, api_provider)\n",
    "    cleaned_code = clean_llm_output(generated_monolithic_code, language='javascript')\n",
    "    display(Code(cleaned_code, language='javascript'))\n",
    "    save_artifact(cleaned_code, \"app/day8_login_monolithic.js\")\n",
    "else:\n",
    "    print(\"Skipping UI generation because no valid model is configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to refactor the monolithic code into smaller components.\n",
    "refactor_ui_prompt = f\"\"\"\n",
    "You are a senior frontend developer who champions clean code. Refactor the provided Reach component code into smaller, reusable components.\n",
    "\n",
    "** Context: **\n",
    "<code>\n",
    "{cleaned_code}\n",
    "</code>\n",
    "\n",
    "**Refactoring Requirements:**\n",
    "1.  Create smaller, reusable sub-components where appropriate. For example, the button and the input fields are good candidates for their own components (e.g., `InputWithIcon`, `LoginButton`).\n",
    "2.  The final output should be a single file containing the definitions for the new, smaller components and the main `LoginForm` component that uses them.\n",
    "3.  Ensure the final visual output remains identical to the original.\n",
    "\n",
    "output only the raw, complete, refactored javascript code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring UI into Components ---\")\n",
    "if cleaned_code:\n",
    "    refactored_code = get_completion(refactor_ui_prompt, client, model_name, api_provider)\n",
    "    cleaned_refactored_code = clean_llm_output(refactored_code, language='javascript')\n",
    "    display(Code(cleaned_refactored_code, language='javascript'))\n",
    "else:\n",
    "    print(\"Skipping refactoring because monolithic code was not generated.\")\n",
    "    cleaned_refactored_code = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65612a",
   "metadata": {},
   "source": [
    "Code was then further refactored based on an iterative development process with chatgpt 4o on chatgpt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0322a2",
   "metadata": {},
   "source": [
    "## BACKEND REFACTORING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7694e6",
   "metadata": {},
   "source": [
    "At this stage we took the main_in_meomory.py and provided it to ChatGPT alongside the instructions from the next step in the lab to intergrate live database logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from typing import Optional, List\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, Depends\n",
    "from pydantic import BaseModel, EmailStr, Field\n",
    "from sqlalchemy import create_engine, Column, Integer, String, DateTime, ForeignKey, Text, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, Session\n",
    "\n",
    "# =====================\n",
    "#   FastAPI Setup\n",
    "# =====================\n",
    "app = FastAPI()\n",
    "\n",
    "# =====================\n",
    "#   Database Setup\n",
    "# =====================\n",
    "DATABASE_URL = \"sqlite:///./app.db\"\n",
    "engine = create_engine(DATABASE_URL, connect_args={\"check_same_thread\": False})\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "# =====================\n",
    "#   SQLAlchemy Models\n",
    "# =====================\n",
    "\n",
    "class UserDB(Base):\n",
    "    __tablename__ = \"users\"\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    email = Column(String, unique=True, index=True, nullable=False)\n",
    "    password_hash = Column(String, nullable=False)\n",
    "    display_name = Column(String)\n",
    "    created_at = Column(DateTime, nullable=False)\n",
    "    updated_at = Column(DateTime)\n",
    "\n",
    "class MoodDB(Base):\n",
    "    __tablename__ = \"moods\"\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    user_id = Column(Integer, ForeignKey(\"users.id\"))\n",
    "    mood = Column(String)\n",
    "    mood_date = Column(Date)\n",
    "    created_at = Column(DateTime)\n",
    "\n",
    "class PromptDB(Base):\n",
    "    __tablename__ = \"prompts\"\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    prompt_text = Column(String)\n",
    "    created_at = Column(DateTime)\n",
    "\n",
    "class JournalDB(Base):\n",
    "    __tablename__ = \"journal\"\n",
    "    id = Column(Integer, primary_key=True, index=True)\n",
    "    user_id = Column(Integer, ForeignKey(\"users.id\"))\n",
    "    prompt_id = Column(Integer, ForeignKey(\"prompts.id\"), nullable=True)\n",
    "    entry_date = Column(Date)\n",
    "    content = Column(Text)\n",
    "    created_at = Column(DateTime)\n",
    "\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\n",
    "# =====================\n",
    "#   Pydantic MODELS\n",
    "# =====================\n",
    "\n",
    "class UserBase(BaseModel):\n",
    "    email: EmailStr\n",
    "    display_name: Optional[str] = None\n",
    "\n",
    "class UserCreate(UserBase):\n",
    "    password: str = Field(..., min_length=6)\n",
    "\n",
    "class User(UserBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "    updated_at: Optional[datetime] = None\n",
    "\n",
    "class MoodBase(BaseModel):\n",
    "    user_id: int\n",
    "    mood: str\n",
    "    mood_date: date\n",
    "\n",
    "class MoodCreate(MoodBase):\n",
    "    pass\n",
    "\n",
    "class Mood(MoodBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "class PromptBase(BaseModel):\n",
    "    prompt_text: str\n",
    "\n",
    "class PromptCreate(PromptBase):\n",
    "    pass\n",
    "\n",
    "class Prompt(PromptBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "class JournalBase(BaseModel):\n",
    "    user_id: int\n",
    "    prompt_id: Optional[int] = None\n",
    "    entry_date: date\n",
    "    content: str\n",
    "\n",
    "class JournalCreate(JournalBase):\n",
    "    pass\n",
    "\n",
    "class Journal(JournalBase):\n",
    "    id: int\n",
    "    created_at: datetime\n",
    "\n",
    "# =====================\n",
    "#   USERS ENDPOINTS\n",
    "# =====================\n",
    "\n",
    "@app.post(\"/users/\", response_model=User)\n",
    "def create_user(user: UserCreate, db: Session = Depends(get_db)):\n",
    "    if db.query(UserDB).filter(UserDB.email == user.email).first():\n",
    "        raise HTTPException(status_code=400, detail=\"Email already registered\")\n",
    "    now = datetime.utcnow()\n",
    "    db_user = UserDB(\n",
    "        email=user.email,\n",
    "        password_hash=user.password,\n",
    "        display_name=user.display_name,\n",
    "        created_at=now,\n",
    "        updated_at=now\n",
    "    )\n",
    "    db.add(db_user)\n",
    "    db.commit()\n",
    "    db.refresh(db_user)\n",
    "    return User(**db_user.__dict__)\n",
    "\n",
    "@app.get(\"/users/\", response_model=List[User])\n",
    "def list_users(db: Session = Depends(get_db)):\n",
    "    users = db.query(UserDB).all()\n",
    "    return [User(**{k: v for k, v in u.__dict__.items() if k != \"password_hash\"}) for u in users]\n",
    "\n",
    "@app.get(\"/users/{user_id}\", response_model=User)\n",
    "def get_user(user_id: int, db: Session = Depends(get_db)):\n",
    "    user = db.query(UserDB).filter(UserDB.id == user_id).first()\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    return User(**{k: v for k, v in user.__dict__.items() if k != \"password_hash\"})\n",
    "\n",
    "@app.put(\"/users/{user_id}\", response_model=User)\n",
    "def update_user(user_id: int, user: UserBase, db: Session = Depends(get_db)):\n",
    "    db_user = db.query(UserDB).filter(UserDB.id == user_id).first()\n",
    "    if not db_user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    for field, value in user.dict().items():\n",
    "        setattr(db_user, field, value)\n",
    "    db_user.updated_at = datetime.utcnow()\n",
    "    db.commit()\n",
    "    db.refresh(db_user)\n",
    "    return User(**{k: v for k, v in db_user.__dict__.items() if k != \"password_hash\"})\n",
    "\n",
    "@app.delete(\"/users/{user_id}\")\n",
    "def delete_user(user_id: int, db: Session = Depends(get_db)):\n",
    "    user = db.query(UserDB).filter(UserDB.id == user_id).first()\n",
    "    if not user:\n",
    "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
    "    db.query(MoodDB).filter(MoodDB.user_id == user_id).delete()\n",
    "    db.query(JournalDB).filter(JournalDB.user_id == user_id).delete()\n",
    "    db.delete(user)\n",
    "    db.commit()\n",
    "    return {\"msg\": \"Deleted\"}\n",
    "\n",
    "# =====================\n",
    "#   MOODS ENDPOINTS\n",
    "# =====================\n",
    "\n",
    "@app.post(\"/moods/\", response_model=Mood)\n",
    "def create_mood(mood: MoodCreate, db: Session = Depends(get_db)):\n",
    "    if not db.query(UserDB).filter(UserDB.id == mood.user_id).first():\n",
    "        raise HTTPException(status_code=400, detail=\"User does not exist\")\n",
    "    db_mood = MoodDB(**mood.dict(), created_at=datetime.utcnow())\n",
    "    db.add(db_mood)\n",
    "    db.commit()\n",
    "    db.refresh(db_mood)\n",
    "    return Mood(**db_mood.__dict__)\n",
    "\n",
    "@app.get(\"/moods/\", response_model=List[Mood])\n",
    "def list_moods(db: Session = Depends(get_db)):\n",
    "    return [Mood(**m.__dict__) for m in db.query(MoodDB).all()]\n",
    "\n",
    "@app.get(\"/moods/{mood_id}\", response_model=Mood)\n",
    "def get_mood(mood_id: int, db: Session = Depends(get_db)):\n",
    "    mood = db.query(MoodDB).filter(MoodDB.id == mood_id).first()\n",
    "    if not mood:\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    return Mood(**mood.__dict__)\n",
    "\n",
    "@app.put(\"/moods/{mood_id}\", response_model=Mood)\n",
    "def update_mood(mood_id: int, mood: MoodBase, db: Session = Depends(get_db)):\n",
    "    db_mood = db.query(MoodDB).filter(MoodDB.id == mood_id).first()\n",
    "    if not db_mood:\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    for field, value in mood.dict().items():\n",
    "        setattr(db_mood, field, value)\n",
    "    db.commit()\n",
    "    db.refresh(db_mood)\n",
    "    return Mood(**db_mood.__dict__)\n",
    "\n",
    "@app.delete(\"/moods/{mood_id}\")\n",
    "def delete_mood(mood_id: int, db: Session = Depends(get_db)):\n",
    "    mood = db.query(MoodDB).filter(MoodDB.id == mood_id).first()\n",
    "    if not mood:\n",
    "        raise HTTPException(status_code=404, detail=\"Mood not found\")\n",
    "    db.delete(mood)\n",
    "    db.commit()\n",
    "    return {\"msg\": \"Deleted\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b2080",
   "metadata": {},
   "source": [
    "For the next step we provided our main.py to GPT with prompting to generate baseline unit tests as well as the security_review.md outlining potential vulnerabilities in the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380c2c1",
   "metadata": {},
   "source": [
    "At this stage we provided our main.py to GPT and prompted it \"can you help me think through what it looks like for a user to use this application\" after which it provided info that revealed that the desired end flow was not implemented. So we followed up with \n",
    "\n",
    "\"I think we want to do some of the basline improvements here. This isn't a prod app but we are showing it off so it's good to use best practices. Also think the logic for endpoints or possibly even the schema maybe needs adjustments. We want for the flow to be log in page -> Mood logging page with possibly some metrics on display, and then finally the journal page that will provide a prompt based off of your mood and displays analytics/previous journals in cards\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfcc90",
   "metadata": {},
   "source": [
    "That sounds like a great move — making it polished and best-practice-aligned will help a lot during the demo. Here's a breakdown of what I recommend you tackle next, based on your goals.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Phase 1: Baseline Best Practices\n",
    "\n",
    "### 🔐 Password Hashing\n",
    "\n",
    "* **Replace** raw storage of `user.password` with a hashed version.\n",
    "* **Use:**\n",
    "\n",
    "```python\n",
    "from passlib.context import CryptContext\n",
    "\n",
    "pwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n",
    "\n",
    "def hash_password(password: str) -> str:\n",
    "    return pwd_context.hash(password)\n",
    "```\n",
    "\n",
    "* In your `/users/` creation route:\n",
    "\n",
    "```python\n",
    "password_hash = hash_password(user.password)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 Add Basic Login Endpoint\n",
    "\n",
    "* New route: `POST /login`\n",
    "* Input: `{ \"email\": \"user@example.com\", \"password\": \"plaintext\" }`\n",
    "* Action:\n",
    "\n",
    "  * Look up user by email\n",
    "  * Use `pwd_context.verify(password, stored_hash)` to check password\n",
    "* Output: (for demo) a success message or token placeholder\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Phase 2: Adjust Schema and Endpoint Logic\n",
    "\n",
    "### ✏️ Schema Changes (Pydantic & DB)\n",
    "\n",
    "* `MoodDB`: consider adding an optional `notes` field\n",
    "* `JournalDB`: consider linking to a `mood_id` for prompt inference\n",
    "\n",
    "### 🔄 Endpoint Refinements\n",
    "\n",
    "* `/moods/`:\n",
    "\n",
    "  * Add analytics fields like `average_mood`, `most_common_mood`, etc.\n",
    "  * Support filtering by `user_id` or date range\n",
    "\n",
    "* `/journal/`:\n",
    "\n",
    "  * Enhance `POST` logic to:\n",
    "\n",
    "    * auto-select a prompt based on recent mood\n",
    "    * embed previous journal summaries in the response\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 Phase 3: UX Flow Alignment\n",
    "\n",
    "### 1. **Login Page**\n",
    "\n",
    "* Form sends request to `POST /login`\n",
    "* Success = redirect to mood log page\n",
    "\n",
    "### 2. **Mood Logging Page**\n",
    "\n",
    "* `POST /moods/`\n",
    "* Fetches metrics from `GET /moods/?user_id=X`\n",
    "\n",
    "  * Display trends (avg, last 7 days, etc.)\n",
    "\n",
    "### 3. **Journal Page**\n",
    "\n",
    "* On load, backend:\n",
    "\n",
    "  * Fetches recent mood\n",
    "  * Suggests a prompt\n",
    "  * Returns cards:\n",
    "\n",
    "    * Prompt + form\n",
    "    * Past journal entries\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to:\n",
    "\n",
    "* Start by implementing password hashing + login route?\n",
    "* Or sketch out the adjusted `journal` and `mood` endpoint structure first?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7903fe1",
   "metadata": {},
   "source": [
    "We followed up on the advice given and implemented jwt hashed tokens when a user logs in and then adjusted the relevant endpoints to be protected to the user that is logged in, as well as the login endpoint we were missing for it all to work properly. Used GPT to help with dependency issues here as well around jwt.\n",
    "\n",
    "Went back and forth with GPT a few times to refactor and clean the main.py until it satisifed our requirements, and aligned with best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940055f2",
   "metadata": {},
   "source": [
    "Once the main.py was refactored and tested somewhat in the swagger ui and the frontend components were mostly done we spent a bit of time figuring out our integration with React."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705bfc7",
   "metadata": {},
   "source": [
    "Once we were able to serve the React frontend as well as test the backend we started integrating the connection between them. We provided the main.py to GPT as context as well as the baseline component and asked it to incorporate our endpoints. We set up the login and users endpoints first as the most the other relevant routes are protected and require being logged in. Then we set up the mood selector page to work with the logged in user and store a persons daily mood. Then finally we set up the journal page to keep the state of the logged in user + the mood they just looged to pull a prompt aligned with that mood from the backend to let them input text around that mood/prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a07bfb0",
   "metadata": {},
   "source": [
    "Once the endpoints were working and it came together pretty easily and quickly with GPT's assistance we decided to do some improvements on the overall flow of using the app. With prompting back and forth we decided to lock a user to only logging one mood a day with clear visual signals to this, we made it so that when a user signs up for a new account that it automatically logs them in and takes them to the mood selector page, we adjusted it so that when the journal is submitted it takes the user back to their mood page with the analytics and a card for recent journals.\n",
    "\n",
    "This integration happened surprisingly quicly and easily and GPT was able to easily handle any issues we had with intelligent prompting around our goals. At this stage we decided to add in a small feature to integrate using AI directly into the application, making a call when submitting journals so that the llm will analyze your journal entires in a meaningful way on the analytics page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985a9d6",
   "metadata": {},
   "source": [
    "# Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67d90a",
   "metadata": {},
   "source": [
    "## 🤖 How We Used AI During the Software Development Life Cycle (SDLC)\n",
    "\n",
    "As part of building our mental health journaling application, we actively used AI tools — particularly ChatGPT — to support and accelerate every phase of the Software Development Life Cycle (SDLC). This not only enhanced productivity and collaboration but also gave us hands-on experience integrating AI into modern software workflows.\n",
    "\n",
    "### 📋 Requirements & Planning\n",
    "- Used AI to clarify vague requirements and break them down into specific frontend and backend tasks.\n",
    "- Helped brainstorm feature sets, such as mood tracking, journal prompts, and potential AI-generated feedback for journal entries.\n",
    "\n",
    "### 💻 Development & Debugging\n",
    "- Generated boilerplate code for FastAPI endpoints, SQLite schema creation, and React components.\n",
    "- Identified and resolved issues quickly — for example, debugging login problems caused by bcrypt hash mismatches and incorrect routing.\n",
    "- Assisted in converting static seed SQL into Python seed scripts and adapting them for one-time user setup.\n",
    "\n",
    "### 🧪 Testing & Demo Data\n",
    "- Helped design seed data (users, prompts, journals, moods) to populate the database for demo purposes.\n",
    "- Simplified the creation of test accounts and ensured consistent test flows, which improved reliability during demonstrations.\n",
    "\n",
    "### 🎨 UI/UX Improvements\n",
    "- Advised on Tailwind CSS usage to make login and signup forms more visually appealing and accessible.\n",
    "- Helped refine component layout, spacing, and color gradients to align with the app's tone and audience.\n",
    "\n",
    "### 🔒 Security Best Practices\n",
    "- Recommended password hashing via `bcrypt` and secure token storage with JWTs in localStorage.\n",
    "- Reviewed and reinforced safe input handling in the backend (e.g. request validation and error handling).\n",
    "\n",
    "### 🧠 AI-Powered Feature Design\n",
    "- Supported the development of future-facing features like journal feedback and summaries using LLMs.\n",
    "- Helped us craft prompts to generate reflective AI responses based on journal content — setting the foundation for a guided journaling experience.\n",
    "\n",
    "### 📝 Documentation & Reflection\n",
    "- Generated concise explanations and retrospectives for use in documentation, team discussions, and this very summary.\n",
    "- Helped translate technical decisions into clear, professional communication suitable for instructors and stakeholders.\n",
    "\n",
    "---\n",
    "\n",
    "By integrating AI into our development workflow, we not only built a functional application, but also explored how modern developer tools can enhance collaboration, creativity, and speed throughout the SDLC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f382938",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
